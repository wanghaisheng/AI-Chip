## 如何看待巨头和国内创业团队之间的对抗
当前，全球 3D 视觉领域市场主要由英特尔、索尼等海外大厂占领：“像索尼、ST 这样的大企业，如果聚焦到某一个细分领域，其实也是小团队在运营。所以国内企业的
竞争对象，可能只是大企业中的一个小团队。”
从另一个角度来看，“不论是做算法的公司，还是做 AI 芯片的公司，最终看得还是如何在细分应用场景中落地，能不能实现更真实的效果和更
好的用户体验。从这个点来说，国内芯片厂商与国内客户在地理位置上更为接近，更快的响应速度、更好的支持服务，也可以成为国内厂商在市场竞争中的优势

## 困境

真正的AI不仅局限于图像处理，还应该兼具视听等多种感官能力。AI的通用性首当其冲。当下AI产业的突破仍处于单点突破期。由于应用背景明确、数据积累丰富，在翻译、图像检测等一些特定的领域里，AI的能力已经超越
人类。但是，真正的AI通用芯片应该具备视、听、触等多种能力，而不是单独针对某个领域进行优化。因此，就像人一样，需要各种传感器同时起作用，这样带给用户的体验才会更好。

边缘侧AI之所以没有普及，因为AI芯片在成本、能耗、算力、通用性、生态等方面仍有不足，只有足够轻量化、低功耗的AI芯片才能落地于边缘
侧设备。

生态也是重要一环，需要芯片厂商一方面从芯片厂商延伸至开发板、算法以及边缘侧的解决方案，同时向外与AI厂商建立合作关系。
与高校建立实训基地，合办大学生创新创业训练计划项，与下游开发板开发商(淘宝已有的公司或者个人)合作，加入paddlepaddle、腾讯tnn等平台工具生态，利用其已有模型加速场景落地，软件生态建设上参考亚马逊skill机制，开放sdk和starterkit，共建开发者生态，向私有云供应商输出芯片或者模组/解决方案

![image](https://user-images.githubusercontent.com/2363295/166143068-9c71759b-5897-45d3-af46-52c9587c7073.png)


![image](https://user-images.githubusercontent.com/2363295/166143373-d2c7ef62-2716-4182-81b3-a89165879b13.png)

AI 芯片产业的繁荣发展需要有清晰合理的评测标准和工具作为技术支持。国内外目前有多种AI 芯片评测工具，如哈佛大学的 Fathom、寒武纪的 BenchIP、百度研究院的 DeepBench、斯坦福
大学的 DAWNBench，以及由谷歌牵头推出的 MLPerf 等。我国 AI 芯片评测方法和工具的研发还处于起步阶段，远不能满足国内实际需求。因此，我国应加快 AI 芯片测评方法及工具的研究开
发速度，搭建 AI 芯片评测服务平台。


![image](https://user-images.githubusercontent.com/2363295/166141708-0e0809f4-8424-493d-a48c-97c45dfdc526.png)
高校教师是生态构建的星星之火。企业联合高校开展师资培训是企业在建立人工智能生态时使用的一种策略，希望借由高校作为抓手和落脚点，通过开展师资培训向高校教师推广好用的教学产品和实践平台，打通人工智能教育的全链路，实现技术成果转化到落地应用的无缝连接。截至 2020 年 12 月，超过 200 所高校的近300 位老师已在百度的 AI Studio 平台开设课程并带领学生完成实践项目学习；AI Studio 平台上已经积累了 30 多万开发者、40 多万的案例工程和数据集、4 000 多精品课程内容，由此可见，百度通过联合高校开展师资培训建立人工智能生态取得了显著的成果。

![image](https://user-images.githubusercontent.com/2363295/166142953-488db8cf-8a1d-4828-a8ad-8c2f34fde9e4.png)

![image](https://user-images.githubusercontent.com/2363295/166142909-9a6d2c85-8674-4961-af96-d40503c3a60c.png)

## 公司catalog 竞品

![image](https://user-images.githubusercontent.com/2363295/166143783-b672c4d4-1c96-4b12-8b0e-b1fd4adaeed0.png)

公司名称 融资阶段 技术特色 产品系列  应用场景 客户数量 论文数量 github repo数量 微信指数

1 中科寒武纪 思元 270 2019 ASIC 云端推理
思元 220 2019 ASIC 边缘推理
2 地平线机器人 征程二代 2019 ASIC 边缘推理
旭日 2019 ASIC 边缘推理
3 华为 昇腾 310 2018 达芬奇架构 边缘推理
昇腾 910 2019 达芬奇架构 云端训练
4 中星微电子 星光智能一号
VC0758
2019 ASIC 边缘推理
5 云天励飞 DeepEye1000 2019 SoC 边缘推理
6 灵汐科技 天机芯 2019 类脑芯片 边缘推理
7 比特大陆 算丰 BM1684 2019 ASIC 云端推理
算丰 BM1880 2018 ASIC 边缘推理
8 百度 昆仑 2018 FPGA 云端训练、云端推理
9 平头哥 含光 800 2019 FPGA 云端推理
玄铁 910 2019 RISC-V 边缘推理
10 依图科技 求索 2019 ARM 架构 云端推理

模拟与混合信号芯片设计公司聚芯微电子  | 数亿元 C 轮融资；| ToF（Time of Flight）3D 图像传感器| 扫地机
器人、人脸识别支付、AR/VR、自动驾驶等 |

人工智能视觉芯片研发及基础算力平台公司爱芯科技 | A+轮融资 数亿元人民币；

埃瓦科技 |亿元级 A 轮融资|传感器与计算模块相结合，形成 3D 人脸识别模组，可应用于门锁、门禁、考勤机等多个场
景当中|3D 人脸识别智能门锁

爱芯元智成立于 2019 年 5 月，专注于打造高性能、低功耗的 AI 视觉处理器芯片。核心技术产品支持多种AI 视觉任务，广泛适用于智慧城市、智能社区、智能驾驶、智慧零售、智能家居、智能穿戴等多个领域。爱
芯元智自主研发的第 1 颗 AI 视觉处理芯片 AX630A 已 在 2020 年 12 月实现量产，目前已正式出货；第 2 颗芯片 AX620A 也已经于 2021 年 7 月成功点亮，
AX630A 是高端旗舰产品，AX620A面向主流市场。它们都强调高算力，低功耗，高算力利用率。
1）AX630A 是爱芯元智正式量产的第一颗芯片，等效算力在 int4 的情况下是约是 28.8T。该芯片的另一特点是在如此高算力的情况下，功耗可控，约为 3 W。低功耗对于很多边缘测产品是很重要的，因为它们往往是在户外的，夏天的环境温度有时可达 40、50 ℃，因此功耗对于这类产品的稳定性有非常大的影响。
2）AX620A 是爱芯元智研发的第二颗芯片，目前已经开始客户推广，计划在 2021 年年底量产。爱芯希望用这颗芯片面对主流的产品市场，大概是 4K 30 帧以下，500 万或 400 万像素的市场需求。AX620A 的另一个特点也是低功耗：在分辨率较小的 1 080P 情况下，功耗可小于 1 W，可用于电池供电的边缘侧产品

嘉楠科技于2018年 9月6日发布了针对于边缘侧的AI芯片——堪智K210。该芯片采用了先进的28 nm工艺，配置RISC-V 64位双核CPU。
K210有完全自主研发的神经网络加速器IP，同时具备机器视觉和语音识别能力，可以在超低功耗下进行高速卷积神经网络（CNN）计算。
在机器视觉方面，基于CNN的目标检测和图像分类任务，以及人脸检测和人脸识别，多分类物体检测与识别等，K210都可以独立、实时的获取多种被检测目标的大小与坐标，并标识出被检测目标的种类。
除了机器视觉能力外，K210的一大特色是还具备机器听觉能力。该芯片上带有支持8通道高性能麦克风阵列的音频处理硬件，可以进行硬件加速的实时声源定向与波束形成，无需占用主CPU资源。一颗芯片就可以
实现声源定向、声场成像、波束形成、语音唤醒、语音识别等机器听觉功能
K210的方案已用于智能门锁、智能抄表等业务场景。合作伙伴可以通过嘉楠的SDK（软件开发包）等开发出更多产品。嘉楠希望和合作伙伴一道，构建共赢格局的AIoT商业生态

其生产的国产 AI 芯片可以处理大量数据，以训练人工智能系统，更重要的是，这些芯片皆为数据中心而设计
燧原科技已有3款 AI 芯片面世，分别是针对云端训练场景的“云燧 T10”和“云燧 T11”，针对云
端推理场景的“云燧 i10”，以及与产品配套的“驭算”软件平台。


寒武纪的主营业务是终端智能处理器 IP 授权、云端智能芯片及加速卡业务以及智能计算集群系统，公司主要做集成电路设计环节，采用 Fabless 经营模式。根据相关资
料，早在 2017 年、2018 年，寒武纪的主要收入来自于向华为海思销售终端智能处理器 IP，不过2019 年因华为海思选择了自研人工智能芯片（NPU），寒武纪痛失这一主要客户
。2021 年全年，该公司实现营业收入为 7.21 亿元，同比增长 57.12%；实现净利润-8.47 亿元，较上年同期亏损扩大
94.98%。
 对于增收不增利的表现，寒武纪在公告中称，公司营业收入主要来自于云端产品线、边缘产品线及智能计算集群业务。报告期内，边缘产品线 MLU220 芯片及加速卡落地多家头部企业，实
现近百万片量级的规模化销售，边缘产品线收入较上年同期实现突破性增长；同时依托公司中标江苏昆山的智能计算中心基础设施建设项目，集群业务收入较上年同期实现大幅增长。
 “报告期内，公司发生的研发费用较上年同期增长；同时，因公司 2020 年底及 2021 年实施的股权激励计划，导致本报告期按归属期分摊的股份支付费用增长。”对于净利润亏损，寒武纪方面则解释称，此外，因公司积极发力智能芯片市场推广及生态建设，销售费用有一定增加。

2021. 3 月，天数智芯完成 C 轮 12 亿元人民币融资。同月，壁仞科技完成 B 轮融资，2019 年
成立以来总融资额超 47 亿元人民币。沐曦也在 3 月宣布完成 PreA＋轮融资。
 更早一些，2 月，登临科技已完成 A+轮融资。1 月，燧原科技宣布完成 18 亿元 C 论融资。
去年 8 月，鲲云科技完成数千万元 A+轮融资。
Ｍａｘｉｍ 宣布与专注于人工智能 （ＡＩ）边 缘 计 算 的 ＸａｉｌｉｅｎｔＩｎｃ达成合作，Ｘａｉｌｉｅｎｔ在其 Ｄｅｔｅｃｔｕｍ 专利神经网 络方案中采用 ＭａｘｉｍＩｎｔｅｇｒａｔｅｄ的 ＭＡＸ７８０００超低功耗 神经网络微控制器，检测并锁定视频、图 像 中 的 人 脸。与 传统嵌入式方案相比，Ｘａｉｌｉｅｎｔ的神经网络技术方案将功 耗 降 低 ２５０ 倍 （仅 为 ２８０ 微 焦 耳），每 次 检 测 运 算 只 需 １２ｍｓ，支持网络的实时运行，速率高于当前市场上最高效 的边缘计算人脸检测方案。 家装摄像头、工业级智能安全摄像头以及零售行业的 人脸识别终端大多采用电池供电，类 似 的 ＡＩ系 统 对 功 耗 提出了严格要求，以确保电池在完成充电后支持最长的工 作时间。除了支持单机运行外，ＭａｘｉｍＩｎｔｅｇｒａｔｅｄ的微控 制器与 Ｘａｉｌｉｅｎｔ的神经网络技术相配合，在 边 缘 计 算／云 计算混合系统中，可大幅提升总体系统的电源效率、延 长 电池寿命；此类应用 采 用 低 功 耗“侦 听”模 式，在 侦 测 到 人 脸目标时唤醒更复杂的系统操作。 

Ｍａｘｉｍ 发布具有最小方案尺寸的 ＡＩ系统供电电源芯片组 Ｍａｘｉｍ 推出 ＭＡＸ１６６０２用 于 ＡＩ处理器核供电的双 输出稳压电源和 ＭＡＸ２０７９０智能电源级ＩＣ，帮助高性能、 大功率人工 智 能（ＡＩ）系统开发人员实现最高效率（降 低 能耗成本、减少发热）和最小方案尺寸的设计目标。该 ＡＩ 多相电源芯 片 组 充 分 利 用 ＭａｘｉｍＩｎｔｅｇｒａｔｅｄ的 耦 合 电 感 专利技术对电流纹波的抑制，将效率比竞争方案提高 １％；在１．８ Ｖ 输 出 电 压、２００ Ａ 负 载 条 件 下，效 率 高 于 ９５％。此外，效率 的 提 升 减 少 了１６％ 的 能 源 浪 费。与 竞 争方案相比，芯片组输出电容的尺寸减小了４０％，有 效 降 低总体方案尺寸和电容数量。该芯片组提供可裁剪方案 供用户定制，以满足不同输出电流、不同规格尺寸的要求。 此外，芯片组适用于 ＡＩ边缘计算以及数据中心云计算等 系统的供电设计。


## 客户群


“第一阶段是按规划把芯片做出来，芯片技术门槛很高，实现第一阶段已很不容易，但它其实是三阶段中最简单的——所有的事情都控制在公司内部”。
第二阶段在于有没有人愿意为芯片买单；
第三阶段则是如何把业务规模化，最终实现盈利，

如何寻找与拓展 AI 芯片的市场，是走在这条赛道较前位置的企业所思虑的事情，也事关能
否顺利飞跃“死亡谷”、成为实现自我造血的“瞪羚”。

有市场潜力的区域也将成为这批企业征程的目的地，比如珠三角、长三角、北京等仍是热门之选。

 AI 芯片市场在哪里？
 第一个方向是互联网企业，“到今天为止，我们这类产品（不管训练还是推理芯片）70%以上的市场仍由互联网企业组成，但另外两个方向的市场正在更快速地扩张”。
 第二个方向是垂直行业。比如金融行业已开始大量将 AI 技术应用在每天的业务中，还有交通、医疗、教育、通信等行业，随着 AI 的应用，市场也开始“起来了”。
 “很多传统行业还没开始用（AI 芯片，这也意味着他们也没有使用其他产品，此时选择我们不需要任何迁移成本，我们还可以和客户一起“从头开始” 做深度捆绑，甚至做定制化的解决方案。
地产？线下零售？

安防
安防行业 AI 应用具备场景碎片化这一典 型特征，并且从目前应用较成熟的公安、交通、金 融等场景向教育、司法、智慧园区、智慧社区、工 业安防、城管、物流、移动监控、安防机器人等众 多泛安防垂直场景不断延伸，从而带来在各种场景 下除去人脸识别、视频结构化、物体特征识别等成 熟算法之外的种类繁多、百花齐放的长尾算法。 在云端、边缘、终端等不同的复杂应用下，对 AI 计算芯片的精度、功耗、可靠性、环境适应性、 成本等也提出了不同要求。将合适的算力放到合适 的场景下，适配不同种类、不同计算量、不同框架 的算法模型


第三个方向则是广泛意义上的“新基建”，包括城市建设的算力中心、智慧城市大脑等等，其中有一些领域最好甚至只能采用国产化产品，这对于国内 AI 芯片赛道上的创新
企业来说是一大蓝海，对瞪羚企业的种子选手们也是一大机遇。


我国工业芯片需求巨大，据不完全统计，“十四五”期间，仅电力领域对芯片的市场需求就约达 2000 亿元。随着智能电网的发展，AI 芯片在电力系统的应用也日渐广泛，在
智能电网发、输、变、配、用、调和公司经营管理领域，运用计算机视觉、自然语言理解、机器学习等人工智能技术，能够有效解决现有业务中的难题，大幅提升生产效率和服务水平。

在计算机视觉应用中，安防占比高达 68%，安防行业的海量数据以及事前预防、事中响应、事后


1. 传统摄像头/显示设备/电视机的升级改造。
现在很多摄像头是不带算力的，有智能化升级改造的需求。通常有两种方法：①全部替换；②增加中间节点，即增加智能处理的盒子。
很多做跨境摄像头 平板 电视机等出货量很大

智能 NVR、边缘服务器、巡检机器人、无人机等极端严酷环境下


2. 计算摄影：超越人眼所见。
暗室里的灯全
关了，人眼看不到任何展示，但是相机能够把暗室里的
图像获取出来。关键在于信噪比（SNR），人眼在 SNR
小到一定程度的时候就区分不出来了。芯片处理能够把
噪声抑制下去，这样藏在噪声里的信号就能被恢复出来。
这主要靠计算摄影，通过计算来恢复出来“消失”的信息


3.计算盒子？
边缘智能计算盒，兼顾边云的智能计算模组、云端智能加速卡、智能服务器乃至大规模的超算中心？



可以总结出典型 AI 芯片在不同应用场景下的分类标准: ( 1) 端侧 AI 芯片: 算力＜5 TOPS，功耗＜5 W。 ( 2) 边缘侧 AI 芯片: 算力 5－100 TOPS，功耗 5－ 100 W。( 3) 云侧 AI 芯片: 算力＞100 TOPS，功耗 100 W －300 W。



按技术架构分类
* GPU：即图形处理单元，是一种由大量运算单元组成的大规模并行计算架构芯片，主要用于处理图形、图像领域的海量数据运算。GPU 上集成了规模巨大的计算矩阵，从而具备了更强大的浮点运
算能力和更快的并行计算速度，与 CPU 相比，更加适用于解决人工智能算法的训练难题。英伟达的GPU 目前在人工智能计算市场上占据了主导地位。
* 半定制化 FPGA：即现场可编程门阵列。与GPU 的固定电路不同，使用者可以根据不同的应用需求，使用硬件描述语言对 FPGA 芯片上集成的基本门电路和存储器进行重新定义。按照新的定义
完成烧录后，FPGA 芯片内部的电路就固化成了实际的连线，从而具备了使用者所需要的功能。此类芯片非常适合在芯片功能尚未完全定型、算法仍需不断迭代完善的情况下使用。使用 FPGA 芯片需要
通过定义硬件去实现软件算法，对使用者的技术水平要求较高，因此在设计并实现复杂的人工智能算法方面难度较高。赛灵思和英特尔在 FPGA 领域具有较大的优势。
* 全定制化 ASIC：即专用芯片，是一种根据特殊应用场景要求进行全定制化的专用人工智能芯片。与 FPGA 相比，ASIC 芯片无法通过修改电路进行功能扩展；而与 CPU、GPU 等通用计算芯片
相比，其性能高、功耗低、成本低（见表 1），也很适合应用于对性能功耗比要求极高的移动设备.谷歌公司发布的 TPU 芯片是当前最知名也最有实用价值的 ASIC 芯片。
* 神经拟态芯片：即类脑芯片，是一种对人脑的神经网络结构进行物理模拟的新型芯片架构，通过模拟人脑的神经网络工作机理实现感知和认知等功能 。IBM 研发的 TrueNorth 芯片就是一种典型的类脑芯片，其逻辑结构颠覆了经典冯·诺依曼架构，把定制化的数字处理内核当作神经元，把内存当作突触，CPU、内存及通信元件等完全集成在本地，实现了算存一体，突破了冯·诺依曼架构中 CPU与内存之间的内存墙瓶颈，但目前多数仍是实验室产品。
DSP是一种由大规模集成电路芯片组成的用来完成某种信号处理任务的处理器。DSP善于测量、计算、过滤或压缩连续的真实模拟信号，广泛应用于通信与信息系统、信号与信息处理、自动控制、雷达、航空航
天、医疗、家用电器等领域。针对滤波、矩阵运算、FFT（fast Fourier transformation）等需要大量乘加法运算的特点，DSP内部配有独立的乘法器和加法器，从而大大提高了运算速率。
DSP 种类繁多，目前应用于 AI 领域的 DSP 主要用于处理视觉系统如图像、视频等方面的任务，在自动驾驶、安防监控、无人机和移动终端等领域最为常见。这 些 DSP 中加入了专为深度神经网络定制的加速部件，如矩阵乘和累加器、全连接的激活层和池化层等。由 于 DSP 具有高速、灵活、体积小、低功耗、可编程的特点，非常适合被用在终端设备中，例如手机和摄像头。

1.CPU、GPU、FPGA、ASIC、ASIP等技术路线的各自特性进行分析
（1）传统的 CPU 芯片主要擅长逻辑控制、串行运算等处理，它不太善于复杂的并行计算。为此CPU 设计公司也做出了一些努力，比如在原有的指令集上面加入了单指令多数据 SIMD 的扩展，目的
是让 CPU 指令集获得并行计算处理的能力。但这也仅仅只是作为补充，所以用 CPU 架构设计完整的深
度学习网络计算的智能芯片并不是特别合适。
（2）GPU 采用多核并行计算架构，拥有数量众多的计算单元用于数据处理，适合对密集型数据进行并行计算，可获得高于 CPU 几十倍甚至上千倍的运行速度。在云端，通用 GPU 也因此被广泛应用
于深度神经网络的训练和推理计算中。
（3）ASIC 属于针对特定应用设计的全定制化芯片，随着当前人工智能算法和应用技术的快熟发展，人工智能专用芯片 ASIC 的产业环境也会日渐
成熟。
（4）FPGA 是一种电路可重复编程的半定制化芯片，通过硬件描述语言编程，重组并生成专用电路。FPGA 可以利用门电路直接实现特定算法功能，也可以利用内部乘累加单元（MAC）进行运算，
用户可以自定义这些门电路、计算单元和储存器之间的布线，改变执行方案。FPGA 因其可重构特性具有显著优势，但市场化阻碍主要在于高昂的硬件和开发成本，为实现重构内部硬件存在冗余和空闲，
从而降低了有效计算资源占比，同时 FPGA 采用硬件编程相对复杂，开发验证成本较高。
（5）ASIP 是新型的定制化指令集处理器芯片，它为某个或某类应用专门设计。通过权衡速度、功耗、成本、灵活性等多个方面的设计约束，设计者可以定制 ASIP 以达到最好的平衡点，使得芯片可
适应某类应用的需求，尤其是需要兼顾性能、功耗、成本的嵌入式系统。
2. 从性能、灵活性、通用性、低成本、低功耗等同等参数进行比较
性能的比较主要看单位时间执行运算的次数、峰值性能和平均性能；灵活性主要指对不同应用场景的适应程度；通用性主要表现为对现有软硬件基
础设施的兼容程度；成本主要关注研发成本、部署和运维成本这三个方面；功耗的体现是部署后的额外功耗，其是否影响现有的供电、散热结构等。
（1）CPU 的灵活性和通用性都很高，它适用于各种应用场景，现有架构大多都围绕 CPU 进行设计，软硬件成熟度也很高。但是性能方面有所欠佳，
成本和功耗也不低。
（2）GPU 的性能高，特别适合 AI 应用，尤其表现在深度学习的训练和推断等方面。灵活性和通用性中等，它只适合计算密集型场景，不适合通信密集型场景，由于具有 CUDA、OpenCL 成熟的编
程架构，对软硬件基础设施也有一定的兼容性，但其功耗和成本都极高。
（3）ASIC 的性能极高，比 GPU 还要高一到两个量级。它专门为 AI 应用开发设计，所以灵活性和通用性都较低，不过它具有极低成本和极低功耗
的优势。
（4）FPGA 具有较高性能、灵活性和通用性的优点。它的吞吐量和并行效率都很高，可进行动态编程和部分重构以应用于不同场景，通常采用加
速卡的形式部署其兼容性强，并且它的功耗较低。虽然 FPGA 芯片成本较高，但无需流片大大降低了
研发成本。
（5）ASIP 集合了 FPGA 和 ASIC 各自的优点，不仅可以提供 ASIC 级别的高性能和低功耗，还能提供处理器级别的指令集灵活性，实现可重新编程，更适用于需求尚未被明确定义、需要芯片具备一定
通用性和可编程性的应用场景，满足 AI 算法快速更新迭代的需求，延长芯片使用生命周期

按部署位置分类
* 云端人工智能芯片：这类芯片运算能力强大，功耗较高，一般部署在公有云、私有云、混合云或数据中心、超算等计算基础设施领域，主要用于深度神经网络模型的训练和推理，处理语音、视频、
图像等海量数据，支持大规模并行计算，通常以加速卡的形式集成多个芯片模块，并行完成相关计算任务。
* 边缘端人工智能芯片：这类芯片一般功耗低、体积小、性能要求不高、成本也较低，相比于云端芯片来说，不需要运行特别复杂的算法，只需具备少量的人工智能计算能力，一般部署在智能手机、
无人机、摄像头、边缘计算设备、工控设备等移动设备或嵌入式设备上。


按功能任务分类
* 人工智能训练芯片：训练是指向人工智能算法模型输入大量已标注好的数据和素材，进行“学习”，对模型的参数不断进行优化调整，最终形成一个具备某种特定功能、结果最优的神经网络算法模型；人
工智能训练芯片即是指专门对人工智能训练算法进行优化加速的芯片，由于训练所需的数据量巨大，算法复杂度高，因此，训练芯片对算力、能效、精度等要求非常高，而且还要具备较高的通用性，以支持已
有的多种算法，甚至还要考虑未来的算法的训练。由于对算力有着极高要求，训练芯片一般更适合部署在大型云端设施中，而且多采用“CPU+GPU”“CPU+GPU+加速芯片”等异构模式，加速芯片可以是 GPU 或
FPGA、ASIC 专用芯片等。人工智能训练芯片的市场主要被英伟达的 GPU 和谷歌的 TPU 所占据，英特尔和 AMD 都在积极进入该领域 。

* 人工智能推理芯片：推理是指向已经训练好的人工智能算法模型输入新的数据和素材，经过计算后获得符合人们预期的相应的输出；人工智能推理芯片即是指专门对人工智能推理算法进行优化加
速的芯片，其更加关注能耗、算力、时延、成本等综合因素。其可以部署在云端和边缘端，实现难度和市场门槛相对较低，因此，这一领域的市场竞争者较多。云端推理芯片领域，英伟达、谷歌、
AMD、赛灵思等传统芯片厂商是主要的领导者，国内的寒武纪、燧原科技、比特大陆也推出了性能较高、市场反响不错的自研芯片。终端推理芯片领域，应用场景丰富，市场集中度不高，产品有一定
的多样性，英伟达、英特尔、高通、ARM 等传统芯片大厂在该领域布局较早，国内的寒武纪、地平线、阿里平头哥、云天励飞等新兴企业在垂直行业也有不俗表现


![image](https://user-images.githubusercontent.com/2363295/166143752-ff47109d-1ec6-4bc7-85b7-9559a880467a.png)
![image](https://user-images.githubusercontent.com/2363295/166143765-6c8033d0-4d7f-4d99-b4ec-25cc089924d0.png)



## 案例集

基于自主 AI 芯片的多算法融合应用全流程处理效率优化及实战应用
》多算法融合应用是指在单个计算单元上，同时运行人脸检测、人脸识别、目标检测、行人再识别（ReID）等算法模型，实现多重技术手段的跨视域连续跟踪和识别。由于多算法融合应用的技术难度和算力要求均较高，使得现有的多算法模型融合应用技术大多使用多服务器组合完成，少有多算法融合模型应用在单卡上的落地应用。同时，以往对加密视频流的分析一般需要经过解密、解码与分析分三步在不同设备上进行，使得对加密视频分析整体效率远远低于普通视频流。笔者基于国内自主研发的具有自主知识产权的 Anrui-810 芯片的边缘端计算模组 Anrui-C1 和云端计算卡 Anrui-P20，对多算法融合应用及加密视频流分析效率进行了优化并落地试用，在永州市雪亮工程项目中及太原市试点的实际监控场景中进行了实战应用。实战结果显示，自主 AI 芯片方案对比海思 Hi3559A、英伟达 Jetson Xavier NX 与英伟达 T4 方案在全流程完整应用时占有大幅优势，尤其对加密视频流分析效率优势更加突出。

基于机器视觉技术的自动爬楼轮椅
》：目前，大多数轮椅不能自动识别楼梯高度和攀爬楼梯，只能在平坦的道路上使用，并且很多地方没有轮椅的专
用通道，导致外出时必须有人陪同，给人们带来了很多困扰。针对上述问题，设计出一种基于机器视觉技术的可识别楼梯阶
数并自动攀爬楼梯的轮椅，以 STM32F103C8T6 为核心控制器，利用电机、红外传感器、MPU6050 模块、K210 模块、ESP8266
模块以及 OLED 模块实现主要功能。该装置使用多个升杆电机组合，基于动力学原理、机械原理，保证低价格的同时可实现
在没有人辅助的情况下，轻松上下楼，其能够保障使用者安全的同时，也能给其家属及朋友带来很多方便。



![image](https://user-images.githubusercontent.com/2363295/166143832-81b286bb-f9cb-48a6-8331-9cc9ae0a0692.png)

![image](https://user-images.githubusercontent.com/2363295/166143863-d164a38f-e9db-4cb3-8573-f8c9ce486912.png)

